/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

var D=Object.defineProperty;var X=Object.getOwnPropertyDescriptor;var Q=Object.getOwnPropertyNames;var Z=Object.prototype.hasOwnProperty;var tt=(n,r)=>{for(var t in r)D(n,t,{get:r[t],enumerable:!0})},et=(n,r,t,s)=>{if(r&&typeof r=="object"||typeof r=="function")for(let e of Q(r))!Z.call(n,e)&&e!==t&&D(n,e,{get:()=>r[e],enumerable:!(s=X(r,e))||s.enumerable});return n};var st=n=>et(D({},"__esModule",{value:!0}),n);var at={};tt(at,{default:()=>N});module.exports=st(at);var y=require("obsidian");function h(n,r){return new Promise((t,s)=>{let e=setTimeout(()=>{clearInterval(a),t()},n),a=setInterval(()=>{r.cancelled&&(clearTimeout(e),clearInterval(a),s(new Error("Processing cancelled by user during API retry wait.")))},100)})}async function K(n,r){try{let t,s,e={method:"GET"};switch(n){case"ollama":if(s=`${r.customEndpoint}/tags`,e.headers={"Content-Type":"application/json"},t=await fetch(s,e),!t.ok)throw new Error(`Ollama API error: ${t.status} - ${await t.text()}`);return await t.json(),{success:!0,message:`Successfully connected to Ollama at ${r.customEndpoint} and listed models.`};case"lmstudio":let a=`${r.customEndpoint}/chat/completions`,o={method:"POST",headers:{"Content-Type":"application/json",Authorization:`Bearer ${r.apiKey||"EMPTY"}`},body:JSON.stringify({model:r.model,messages:[{role:"system",content:"You are a helpful assistant"},{role:"user",content:"Hello"}],temperature:.7,max_tokens:10})};try{if(t=await fetch(a,o),t.ok){try{await t.json()}catch(l){console.warn("LMStudio test connection response was not valid JSON, but status was OK. Assuming success.")}return{success:!0,message:`Successfully connected to LMStudio API at ${r.customEndpoint} using model '${r.model}'.`}}else{let l=await t.text();throw l.includes("Could not find model")?new Error(`LMStudio API error: Model '${r.model}' not found or loaded on the server.`):new Error(`LMStudio API error: ${t.status} - ${l}`)}}catch(l){let i=l instanceof Error?l.message:String(l);throw new Error(`LMStudio API connection failed: ${i}. Is the server running at ${r.customEndpoint}?`)}case"openrouter":if(s="https://openrouter.ai/api/v1/chat/completions",e.method="POST",e.headers={"Content-Type":"application/json",Authorization:`Bearer ${r.apiKey}`},e.body=JSON.stringify({model:r.model,messages:[{role:"user",content:"Test connection"}],max_tokens:1,temperature:0}),t=await fetch(s,e),!t.ok)throw new Error(`OpenRouter API error: ${t.status} - ${await t.text()}`);return await t.json(),{success:!0,message:`Successfully connected to OpenRouter API using model '${r.model}'.`};case"openai":if(s=`${r.customEndpoint||"https://api.openai.com/v1"}/models`,e.headers={Authorization:`Bearer ${r.apiKey}`},t=await fetch(s,e),t.ok||(s=`${r.customEndpoint||"https://api.openai.com/v1"}/chat/completions`,e.method="POST",e.headers={...e.headers,"Content-Type":"application/json"},e.body=JSON.stringify({model:r.model,messages:[{role:"user",content:"Test"}],max_tokens:1,temperature:0}),t=await fetch(s,e)),!t.ok)throw new Error(`OpenAI API error: ${t.status} - ${await t.text()}`);return await t.json(),{success:!0,message:"Successfully connected to OpenAI API."};case"deepseek":if(s="https://api.deepseek.com/v1/models",e.headers={Authorization:`Bearer ${r.apiKey}`},t=await fetch(s,e),t.ok||(s="https://api.deepseek.com/v1/chat/completions",e.method="POST",e.headers={...e.headers,"Content-Type":"application/json"},e.body=JSON.stringify({model:r.model,messages:[{role:"user",content:"Test"}],max_tokens:1,temperature:0}),t=await fetch(s,e)),!t.ok)throw new Error(`${n} API error: ${t.status} - ${await t.text()}`);return await t.json(),{success:!0,message:`Successfully connected to ${n} API.`};case"mistral":if(s="https://api.mistral.ai/v1/models",e.headers={Authorization:`Bearer ${r.apiKey}`},t=await fetch(s,e),t.ok||(s="https://api.mistral.ai/v1/chat/completions",e.method="POST",e.headers={...e.headers,"Content-Type":"application/json"},e.body=JSON.stringify({model:r.model,messages:[{role:"user",content:"Test"}],max_tokens:1,temperature:0}),t=await fetch(s,e)),!t.ok)throw new Error(`Mistral API error: ${t.status} - ${await t.text()}`);return await t.json(),{success:!0,message:"Successfully connected to Mistral API."};case"anthropic":if(s=`${r.customEndpoint}/v1/messages`,e.method="POST",e.headers={"Content-Type":"application/json","x-api-key":r.apiKey,"anthropic-version":"2023-06-01"},e.body=JSON.stringify({model:r.model,messages:[{role:"user",content:"Test"}],max_tokens:1}),t=await fetch(s,e),!t.ok)throw new Error(`Anthropic API error: ${t.status} - ${await t.text()}`);return await t.json(),{success:!0,message:"Successfully connected to Anthropic API."};case"google":if(s=`${r.customEndpoint||"https://generativelanguage.googleapis.com"}/v1beta/models/${r.model}:generateContent?key=${r.apiKey}`,e.method="POST",e.headers={"Content-Type":"application/json"},e.body=JSON.stringify({contents:[{role:"user",parts:[{text:"Test"}]}],generationConfig:{maxOutputTokens:1,temperature:0}}),t=await fetch(s,e),!t.ok)throw new Error(`Google API error: ${t.status} - ${await t.text()}`);return await t.json(),{success:!0,message:"Successfully connected to Google API."};case"azureopenai":if(!r.customEndpoint||!r.model)throw new Error("Azure requires a Custom Endpoint and Model (Deployment Name).");if(s=`${r.customEndpoint}/openai/deployments/${r.model}/chat/completions?api-version=2024-02-15-preview`,e.method="POST",e.headers={"Content-Type":"application/json","api-key":r.apiKey},e.body=JSON.stringify({messages:[{role:"user",content:"Test"}],max_tokens:1,temperature:0}),t=await fetch(s,e),!t.ok)throw new Error(`Azure OpenAI API error: ${t.status} - ${await t.text()}`);return await t.json(),{success:!0,message:`Successfully connected to Azure OpenAI deployment '${r.model}'.`};default:return{success:!1,message:`Connection test not implemented for provider: ${n}`}}}catch(t){let s=t instanceof Error?t.message:String(t);return console.error(`Connection test failed for ${n}:`,t),{success:!1,message:`Connection failed: ${s}`}}}async function w(n,r,t,s,e,a,o){let l=null,i=e.enableStableApiCall?e.apiCallMaxRetries+1:1,p=e.enableStableApiCall?e.apiCallInterval:0;for(let c=1;c<=i;c++){if(a.cancelled)throw new Error("Processing cancelled by user before API attempt.");let m=new AbortController;a.abortController=m;try{return await o(r,t,s,m.signal,e,a)}catch(u){let g=u instanceof Error?u.message:String(u);if(l=u instanceof Error?u:new Error(g),console.warn(`${n} API Call: Attempt ${c} failed: ${g}`),m.signal.aborted||g.includes("cancelled by user"))throw new Error("API call cancelled by user.");let E=g.match(/API error: (\d+)/),f=E?parseInt(E[1],10):null;if(f&&(f===400||f===401||f===403||f===404))throw l;if(a.cancelled)throw new Error("Processing cancelled by user during API retry sequence.");c<i&&(a.log(`Waiting ${p} seconds before retry ${c+1}...`),await h(p*1e3,a))}finally{a.abortController===m&&(a.abortController=null)}}throw console.error(`${n} API Call: All ${i} attempts failed.`),l||new Error(`${n} API call failed after multiple retries.`)}async function j(n,r,t,s,e,a){var c,m,u;if(!n.apiKey)throw new Error("API key is missing for OpenAI provider.");let o=n.customEndpoint||"https://api.openai.com/v1",l={model:n.model,messages:[{role:"system",content:r},{role:"user",content:t}],temperature:n.temperature,max_tokens:e.maxTokens};a.log(`Calling OpenAI API at ${o}/chat/completions...`),await h(50,a);let i=await fetch(`${o}/chat/completions`,{method:"POST",signal:s,headers:{"Content-Type":"application/json",Authorization:`Bearer ${n.apiKey}`},body:JSON.stringify(l)});if(a.log(`Received response from OpenAI API. Status: ${i.status}`),await h(50,a),!i.ok){let g=await i.text();throw new Error(`OpenAI API error: ${i.status} - ${g}`)}let p=await i.json();if(!((u=(m=(c=p.choices)==null?void 0:c[0])==null?void 0:m.message)!=null&&u.content))throw new Error("Unexpected response format from OpenAI API");return p.choices[0].message.content}async function _(n,r,t,s,e,a){var c,m,u,g,E;if(!n.apiKey)throw new Error("API key is missing for Google provider.");let o=`${n.customEndpoint||"https://generativelanguage.googleapis.com"}/v1beta/models/${n.model}:generateContent?key=${n.apiKey}`,l={contents:[{role:"user",parts:[{text:`${r}

${t}`}]}],generationConfig:{temperature:n.temperature,maxOutputTokens:e.maxTokens}};a.log(`Calling Google API at ${o}...`),await h(50,a);let i=await fetch(o,{method:"POST",signal:s,headers:{"Content-Type":"application/json"},body:JSON.stringify(l)});if(a.log(`Received response from Google API. Status: ${i.status}`),await h(50,a),!i.ok){let f=await i.text();throw new Error(`Google API error: ${i.status} - ${f}`)}let p=await i.json();if(!((E=(g=(u=(m=(c=p.candidates)==null?void 0:c[0])==null?void 0:m.content)==null?void 0:u.parts)==null?void 0:g[0])!=null&&E.text))throw new Error("Unexpected response format from Google API");return p.candidates[0].content.parts[0].text}async function z(n,r,t,s,e,a){var c,m;if(!n.apiKey)throw new Error("API key is missing for Anthropic provider.");let o=n.customEndpoint||"https://api.anthropic.com",l={model:n.model,messages:[{role:"user",content:`${r}

${t}`}],temperature:n.temperature,max_tokens:e.maxTokens};a.log(`Calling Anthropic API at ${o}/v1/messages...`),await h(50,a);let i=await fetch(`${o}/v1/messages`,{method:"POST",signal:s,headers:{"Content-Type":"application/json","x-api-key":n.apiKey,"anthropic-version":"2023-06-01"},body:JSON.stringify(l)});if(a.log(`Received response from Anthropic API. Status: ${i.status}`),await h(50,a),!i.ok){let u=await i.text();throw new Error(`Anthropic API error: ${i.status} - ${u}`)}let p=await i.json();if(!((m=(c=p.content)==null?void 0:c[0])!=null&&m.text))throw new Error("Unexpected response format from Anthropic API");return p.content[0].text}async function F(n,r,t,s,e,a){var c,m,u;if(!n.apiKey)throw new Error("API key is missing for DeepSeek provider.");let o=n.customEndpoint||"https://api.deepseek.com",l={model:n.model,messages:[{role:"system",content:r},{role:"user",content:t}],temperature:n.temperature,max_tokens:e.maxTokens};a.log(`Calling DeepSeek API at ${o}/chat/completions...`),await h(50,a);let i=await fetch(`${o}/chat/completions`,{method:"POST",signal:s,headers:{"Content-Type":"application/json",Authorization:`Bearer ${n.apiKey}`},body:JSON.stringify(l)});if(a.log(`Received response from DeepSeek API. Status: ${i.status}`),await h(50,a),!i.ok){let g=await i.text();throw new Error(`DeepSeek API error: ${i.status} - ${g}`)}let p=await i.json();if(!((u=(m=(c=p.choices)==null?void 0:c[0])==null?void 0:m.message)!=null&&u.content))throw new Error("Unexpected response format from DeepSeek API");return p.choices[0].message.content}async function G(n,r,t,s,e,a){var c,m,u;if(!n.apiKey)throw new Error("API key is missing for Mistral provider.");let o=n.customEndpoint||"https://api.mistral.ai/v1",l={model:n.model,messages:[{role:"system",content:r},{role:"user",content:t}],temperature:n.temperature,max_tokens:e.maxTokens};a.log(`Calling Mistral API at ${o}/chat/completions...`),await h(50,a);let i=await fetch(`${o}/chat/completions`,{method:"POST",signal:s,headers:{"Content-Type":"application/json",Authorization:`Bearer ${n.apiKey}`},body:JSON.stringify(l)});if(a.log(`Received response from Mistral API. Status: ${i.status}`),await h(50,a),!i.ok){let g=await i.text();throw new Error(`Mistral API error: ${i.status} - ${g}`)}let p=await i.json();if(!((u=(m=(c=p.choices)==null?void 0:c[0])==null?void 0:m.message)!=null&&u.content))throw new Error("Unexpected response format from Mistral API");return p.choices[0].message.content}async function H(n,r,t,s,e,a){var c,m,u;if(!n.apiKey)throw new Error("API key is missing for OpenRouter provider.");let o=n.customEndpoint||"https://openrouter.ai/api/v1",l={model:n.model,messages:[{role:"system",content:r},{role:"user",content:t}],temperature:n.temperature,max_tokens:e.maxTokens};a.log(`Calling OpenRouter API at ${o}/chat/completions...`),await h(50,a);let i=await fetch(`${o}/chat/completions`,{method:"POST",signal:s,headers:{"Content-Type":"application/json",Authorization:`Bearer ${n.apiKey}`},body:JSON.stringify(l)});if(a.log(`Received response from OpenRouter API. Status: ${i.status}`),await h(50,a),!i.ok){let g=await i.text();throw new Error(`OpenRouter API error: ${i.status} - ${g}`)}let p=await i.json();if(!((u=(m=(c=p.choices)==null?void 0:c[0])==null?void 0:m.message)!=null&&u.content))throw new Error("Unexpected response format from OpenRouter API");return p.choices[0].message.content}async function V(n,r,t,s,e,a){var c,m,u;if(!n.apiKey)throw new Error("API key is missing for Azure OpenAI provider.");if(!n.customEndpoint||!n.model)throw new Error("Azure requires a Custom Endpoint and Model (Deployment Name).");let o=`${n.customEndpoint}/openai/deployments/${n.model}/chat/completions?api-version=2024-02-15-preview`,l={messages:[{role:"system",content:r},{role:"user",content:t}],temperature:n.temperature,max_tokens:e.maxTokens};a.log(`Calling Azure OpenAI API at ${o}...`),await h(50,a);let i=await fetch(o,{method:"POST",signal:s,headers:{"Content-Type":"application/json","api-key":n.apiKey},body:JSON.stringify(l)});if(a.log(`Received response from Azure OpenAI API. Status: ${i.status}`),await h(50,a),!i.ok){let g=await i.text();throw new Error(`Azure OpenAI API error: ${i.status} - ${g}`)}let p=await i.json();if(!((u=(m=(c=p.choices)==null?void 0:c[0])==null?void 0:m.message)!=null&&u.content))throw new Error("Unexpected response format from Azure OpenAI API");return p.choices[0].message.content}async function q(n,r,t,s,e,a){var c;let o=n.customEndpoint||"http://localhost:11434",l={model:n.model,messages:[{role:"system",content:r},{role:"user",content:t}],options:{temperature:n.temperature,num_predict:e.maxTokens},stream:!1};a.log(`Calling Ollama API at ${o}/api/chat...`),await h(50,a);let i=await fetch(`${o}/api/chat`,{method:"POST",signal:s,headers:{"Content-Type":"application/json"},body:JSON.stringify(l)});if(a.log(`Received response from Ollama API. Status: ${i.status}`),await h(50,a),!i.ok){let m=await i.text();throw new Error(`Ollama API error: ${i.status} - ${m}`)}let p=await i.json();if(!((c=p.message)!=null&&c.content))throw new Error("Unexpected response format from Ollama");return p.message.content}async function U(n,r,t,s,e,a){var c,m,u;let o=n.customEndpoint||"http://localhost:1234",l={model:n.model,messages:[{role:"system",content:r},{role:"user",content:t}],temperature:n.temperature,max_tokens:e.maxTokens};a.log(`Calling LMStudio API at ${o}/v1/chat/completions...`),await h(50,a);let i=await fetch(`${o}/v1/chat/completions`,{method:"POST",signal:s,headers:{"Content-Type":"application/json",Authorization:`Bearer ${n.apiKey||"EMPTY"}`},body:JSON.stringify(l)});if(a.log(`Received response from LMStudio API. Status: ${i.status}`),await h(50,a),!i.ok){let g=await i.text();throw new Error(`LMStudio API error: ${i.status} - ${g}`)}let p=await i.json();if(!((u=(m=(c=p.choices)==null?void 0:c[0])==null?void 0:m.message)!=null&&u.content))throw new Error("Unexpected response format from LMStudio");return p.choices[0].message.content}var I=class{constructor(){this.name="openai"}async translate(r,t,s,e){let a=s.providerSettings[this.name],o=`Translate the following markdown document to ${t}. It is crucial to preserve ALL markdown formatting, including headings, lists, code blocks, tables, links, and especially image links and their layout. Do NOT add any extra text, comments, or explanations. Only provide the translated content.`;return w(this.name,a,o,r,s,e,(l,i,p,c,m)=>j(l,i,p,c,m,e))}};var v=class{constructor(){this.name="google"}async translate(r,t,s,e){let a=s.providerSettings[this.name],o=`Translate the following markdown document to ${t}. It is crucial to preserve ALL markdown formatting, including headings, lists, code blocks, tables, links, and especially image links and their layout. Do NOT add any extra text, comments, or explanations. Only provide the translated content.`;return w(this.name,a,o,r,s,e,(l,i,p,c,m)=>_(l,i,p,c,m,e))}};var k=class{constructor(){this.name="anthropic"}async translate(r,t,s,e){let a=s.providerSettings[this.name],o=`Translate the following markdown document to ${t}. It is crucial to preserve ALL markdown formatting, including headings, lists, code blocks, tables, links, and especially image links and their layout. Do NOT add any extra text, comments, or explanations. Only provide the translated content.`;return w(this.name,a,o,r,s,e,(l,i,p,c,m)=>z(l,i,p,c,m,e))}};var b=class{constructor(){this.name="deepseek"}async translate(r,t,s,e){let a=s.providerSettings[this.name],o=`Translate the following markdown document to ${t}. It is crucial to preserve ALL markdown formatting, including headings, lists, code blocks, tables, links, and especially image links and their layout. Do NOT add any extra text, comments, or explanations. Only provide the translated content.`;return w(this.name,a,o,r,s,e,(l,i,p,c,m)=>F(l,i,p,c,m,e))}};var $=class{constructor(){this.name="mistral"}async translate(r,t,s,e){let a=s.providerSettings[this.name],o=`Translate the following markdown document to ${t}. It is crucial to preserve ALL markdown formatting, including headings, lists, code blocks, tables, links, and especially image links and their layout. Do NOT add any extra text, comments, or explanations. Only provide the translated content.`;return w(this.name,a,o,r,s,e,(l,i,p,c,m)=>G(l,i,p,c,m,e))}};var O=class{constructor(){this.name="openrouter"}async translate(r,t,s,e){let a=s.providerSettings[this.name],o=`Translate the following markdown document to ${t}. It is crucial to preserve ALL markdown formatting, including headings, lists, code blocks, tables, links, and especially image links and their layout. Do NOT add any extra text, comments, or explanations. Only provide the translated content.`;return w(this.name,a,o,r,s,e,(l,i,p,c,m)=>H(l,i,p,c,m,e))}};var C=class{constructor(){this.name="azureopenai"}async translate(r,t,s,e){let a=s.providerSettings[this.name],o=`Translate the following markdown document to ${t}. It is crucial to preserve ALL markdown formatting, including headings, lists, code blocks, tables, links, and especially image links and their layout. Do NOT add any extra text, comments, or explanations. Only provide the translated content.`;return w(this.name,a,o,r,s,e,(l,i,p,c,m)=>V(l,i,p,c,m,e))}};var L=class{constructor(){this.name="ollama"}async translate(r,t,s,e){let a=s.providerSettings[this.name],o=`Translate the following markdown document to ${t}. It is crucial to preserve ALL markdown formatting, including headings, lists, code blocks, tables, links, and especially image links and their layout. Do NOT add any extra text, comments, or explanations. Only provide the translated content.`;return w(this.name,a,o,r,s,e,(l,i,p,c,m)=>q(l,i,p,c,m,e))}};var B=class{constructor(){this.name="lmstudio"}async translate(r,t,s,e){let a=s.providerSettings[this.name],o=`Translate the following markdown document to ${t}. It is crucial to preserve ALL markdown formatting, including headings, lists, code blocks, tables, links, and especially image links and their layout. Do NOT add any extra text, comments, or explanations. Only provide the translated content.`;return w(this.name,a,o,r,s,e,(l,i,p,c,m)=>U(l,i,p,c,m,e))}};function J(n){switch(n){case"openai":return new I;case"google":return new v;case"anthropic":return new k;case"deepseek":return new b;case"mistral":return new $;case"openrouter":return new O;case"azureopenai":return new C;case"ollama":return new L;case"lmstudio":return new B;default:throw new Error(`Unsupported provider: ${n}`)}}var A={llmProvider:"openai",outputPath:"translations",temperature:.7,maxTokens:2048,targetLanguage:"English",providerSettings:{openai:{name:"openai",apiKey:"",model:"gpt-4o",customEndpoint:"",temperature:.7},google:{name:"google",apiKey:"",model:"gemini-pro",customEndpoint:"",temperature:.7},anthropic:{name:"anthropic",apiKey:"",model:"claude-3-opus-20240229",customEndpoint:"",temperature:.7},deepseek:{name:"deepseek",apiKey:"",model:"deepseek-coder",customEndpoint:"",temperature:.7},mistral:{name:"mistral",apiKey:"",model:"mistral-large-latest",customEndpoint:"",temperature:.7},openrouter:{name:"openrouter",apiKey:"",model:"mistralai/mistral-7b-instruct",customEndpoint:"",temperature:.7},azureopenai:{name:"azureopenai",apiKey:"",model:"gpt-4o",customEndpoint:"",temperature:.7},ollama:{name:"ollama",apiKey:"ollama",model:"llama2",customEndpoint:"http://localhost:11434/v1",temperature:.7},lmstudio:{name:"lmstudio",apiKey:"lmstudio",model:"local-model",customEndpoint:"http://localhost:1234/v1",temperature:.7}},enableStableApiCall:!1,apiCallInterval:5,apiCallMaxRetries:3},P="translator-sidebar-view",W="AI Translator",Y="languages";var d=require("obsidian");var R=class extends d.PluginSettingTab{constructor(t,s){super(t,s);this.plugin=s}display(){let{containerEl:t}=this;t.empty(),new d.Setting(t).setName("LLM Provider").setHeading(),new d.Setting(t).setName("LLM Provider").setDesc("Choose the Large Language Model provider.").addDropdown(e=>e.addOption("openai","OpenAI").addOption("google","Google AI").addOption("anthropic","Anthropic").addOption("deepseek","Deepseek").addOption("mistral","Mistral").addOption("openrouter","OpenRouter").addOption("azureopenai","Azure OpenAI").addOption("ollama","Ollama").addOption("lmstudio","LMStudio").setValue(this.plugin.settings.llmProvider).onChange(async a=>{this.plugin.settings.llmProvider=a,await this.plugin.saveSettings(),this.display()}));let s=this.plugin.settings.providerSettings[this.plugin.settings.llmProvider];s&&(new d.Setting(t).setName(`${this.plugin.settings.llmProvider} details`).setHeading(),new d.Setting(t).setName("API Key").setDesc("Your API key for the selected LLM provider. Note: API keys are provider-specific.").addText(e=>e.setPlaceholder("Enter your API key").setValue(s.apiKey||"").onChange(async a=>{s.apiKey=a,await this.plugin.saveSettings()})),new d.Setting(t).setName("Custom Endpoint").setDesc("Custom API endpoint for the selected provider.").addText(e=>e.setPlaceholder("e.g., http://localhost:1234/v1 or your Azure OpenAI endpoint").setValue(s.customEndpoint||"").onChange(async a=>{s.customEndpoint=a,await this.plugin.saveSettings()})),new d.Setting(t).setName("Model").setDesc("The model to use for translation.").addText(e=>e.setPlaceholder("e.g., gpt-4o").setValue(s.model||"").onChange(async a=>{s.model=a,await this.plugin.saveSettings()})),new d.Setting(t).setName(`Test ${this.plugin.settings.llmProvider} connection`).setDesc("Verify API key, endpoint, and model accessibility.").addButton(e=>e.setButtonText("Test connection").setCta().onClick(async()=>{e.setDisabled(!0).setButtonText("Testing...");let a=new d.Notice(`Testing connection to ${this.plugin.settings.llmProvider}...`,0);try{let o=await K(this.plugin.settings.llmProvider,s);a.hide(),o.success?new d.Notice(`\u2705 Success: ${o.message}`,5e3):new d.Notice(`\u274C Failed: ${o.message}. Check console.`,1e4)}catch(o){let l=o instanceof Error?o.message:String(o);a.hide(),new d.Notice(`Error during connection test: ${l}`,1e4),console.error(`Error testing ${this.plugin.settings.llmProvider} connection from settings:`,o)}finally{e.setDisabled(!1).setButtonText("Test connection")}}))),new d.Setting(t).setName("Translation Settings").setHeading(),new d.Setting(t).setName("Temperature").setDesc("Controls randomness. Higher values make the output more random.").addSlider(e=>e.setLimits(0,1,.1).setValue(this.plugin.settings.temperature).setDynamicTooltip().onChange(async a=>{this.plugin.settings.temperature=a,await this.plugin.saveSettings()})),new d.Setting(t).setName("Max Tokens").setDesc("The maximum number of tokens to generate.").addText(e=>e.setPlaceholder("e.g., 2048").setValue(this.plugin.settings.maxTokens.toString()).onChange(async a=>{this.plugin.settings.maxTokens=parseInt(a),await this.plugin.saveSettings()})),new d.Setting(t).setName("Target Language").setDesc("The language to translate the document into.").addDropdown(e=>{let a={English:"English",Spanish:"Espa\xF1ol",French:"Fran\xE7ais",German:"Deutsch",Chinese:"\u4E2D\u6587",Japanese:"\u65E5\u672C\u8A9E",Korean:"\uD55C\uAD6D\uC5B4",Russian:"\u0420\u0443\u0441\u0441\u043A\u0438\u0439",Portuguese:"Portugu\xEAs",Italian:"Italiano",Arabic:"\u0627\u0644\u0639\u0631\u0628\u064A\u0629",Hindi:"\u0939\u093F\u0928\u094D\u0926\u0940",Bengali:"\u09AC\u09BE\u0982\u09B2\u09BE",Dutch:"Nederlands",Turkish:"T\xFCrk\xE7e",Vietnamese:"Ti\u1EBFng Vi\u1EC7t",Polish:"Polski",Thai:"\u0E44\u0E17\u0E22",Swedish:"Svenska",Indonesian:"Bahasa Indonesia"};for(let o in a)e.addOption(o,a[o]);e.setValue(this.plugin.settings.targetLanguage).onChange(async o=>{this.plugin.settings.targetLanguage=o,await this.plugin.saveSettings()})}),new d.Setting(t).setName("Output Path").setDesc("Path to save translated files.").addText(e=>e.setPlaceholder("e.g., translations/").setValue(this.plugin.settings.outputPath).onChange(async a=>{this.plugin.settings.outputPath=a,await this.plugin.saveSettings()})),new d.Setting(t).setName("Stable API calls").setHeading(),new d.Setting(t).setName("Enable stable API calls (retry logic)").setDesc("On: Automatically retry failed LLM API calls. Off: Fail on first error.").addToggle(e=>e.setValue(this.plugin.settings.enableStableApiCall).onChange(async a=>{this.plugin.settings.enableStableApiCall=a,await this.plugin.saveSettings(),this.display()})),this.plugin.settings.enableStableApiCall&&(new d.Setting(t).setName("Retry interval (seconds)").setDesc("Wait time between retries.").addText(e=>e.setPlaceholder(String(A.apiCallInterval)).setValue(String(this.plugin.settings.apiCallInterval)).onChange(async a=>{let o=parseInt(a,10);!isNaN(o)&&o>=1&&o<=300?this.plugin.settings.apiCallInterval=o:this.plugin.settings.apiCallInterval=A.apiCallInterval,await this.plugin.saveSettings(),this.display()})),new d.Setting(t).setName("Maximum retries").setDesc("Max retry attempts.").addText(e=>e.setPlaceholder(String(A.apiCallMaxRetries)).setValue(String(this.plugin.settings.apiCallMaxRetries)).onChange(async a=>{let o=parseInt(a,10);!isNaN(o)&&o>=0&&o<=10?this.plugin.settings.apiCallMaxRetries=o:this.plugin.settings.apiCallMaxRetries=A.apiCallMaxRetries,await this.plugin.saveSettings(),this.display()})))}};var T=require("obsidian"),S=class extends T.ItemView{constructor(t,s){super(t);this.statusEl=null;this.progressEl=null;this.progressBarContainerEl=null;this.logEl=null;this.logContent=[];this.cancelButton=null;this.isCancelled=!1;this.abortController=null;this.plugin=s}getViewType(){return"translator-sidebar-view"}getDisplayText(){return"AI Translator"}get cancelled(){return this.isCancelled}requestCancel(){var t;this.isCancelled||(this.isCancelled=!0,(t=this.abortController)==null||t.abort(),this.updateStatus("Cancelling...",-1),this.log("User requested cancellation."),this.cancelButton&&(this.cancelButton.disabled=!0))}clearDisplay(){this.isCancelled=!1,this.abortController=null,this.logContent=[],this.logEl&&this.logEl.empty(),this.statusEl&&this.statusEl.setText("Ready"),this.progressEl&&(this.progressEl.dataset.progress="0",this.progressEl.setText(""),this.progressEl.removeClass("is-error")),this.progressBarContainerEl&&this.progressBarContainerEl.addClass("is-hidden"),this.cancelButton&&(this.cancelButton.disabled=!0,this.cancelButton.removeClass("is-active"))}updateStatus(t,s){if(this.statusEl&&this.statusEl.setText(t),this.cancelButton&&this.plugin.getIsBusy()?(this.cancelButton.disabled=!1,this.cancelButton.addClass("is-active")):this.cancelButton&&(this.cancelButton.disabled=!0,this.cancelButton.removeClass("is-active")),s!==void 0&&this.progressEl&&this.progressBarContainerEl)if(this.progressBarContainerEl.removeClass("is-hidden"),s>=0){let e=Math.min(100,Math.max(0,s));this.progressEl.dataset.progress=String(e),this.progressEl.setText(`${Math.round(e)}%`),this.progressEl.removeClass("is-error")}else this.progressEl.dataset.progress="100",this.progressEl.addClass("is-error"),this.progressEl.setText("Cancelled/Error")}log(t){if(this.logEl){let s=`[${new Date().toLocaleTimeString()}]`,e=`${s} ${t}`;this.logContent.push(e);let a=this.logEl.createEl("div",{cls:"translator-log-entry"});a.createEl("span",{text:s,cls:"translator-log-time"}),a.createEl("span",{text:` ${t}`,cls:"translator-log-message"}),this.logEl.scrollTop=this.logEl.scrollHeight}}async onOpen(){let t=this.containerEl.children[1];t.empty(),t.addClass("translator-sidebar-container"),t.createEl("h4",{text:"AI Translator"});let e=t.createDiv({cls:"translator-button-group"}).createEl("button",{text:"Translate Active File",cls:"mod-cta"});e.onclick=async()=>{await this.plugin.translateAndCompareFile()},t.createEl("hr");let a=t.createDiv({cls:"translator-progress-area"});this.statusEl=a.createEl("p",{text:"Ready",cls:"translator-status-text"}),this.progressBarContainerEl=a.createEl("div",{cls:"translator-progress-bar-container is-hidden"}),this.progressEl=this.progressBarContainerEl.createEl("div",{cls:"translator-progress-bar-fill"}),this.cancelButton=a.createEl("button",{text:"Cancel",cls:"translator-cancel-button"}),this.cancelButton.onclick=()=>{this.plugin.cancelTranslation()},t.createEl("hr");let o=t.createDiv({cls:"translator-log-header"});o.createEl("h5",{text:"Log"});let l=o.createEl("button",{text:"Copy Log",cls:"translator-copy-log-button"});l.onclick=()=>{this.logContent.length>0?navigator.clipboard.writeText(this.logContent.join(`
`)).then(()=>new T.Notice("Log copied!"),()=>new T.Notice("Failed to copy log.")):new T.Notice("Log is empty.")},this.logEl=t.createEl("div",{cls:"translator-log-output is-selectable"})}async onClose(){}};var M=require("obsidian"),x=class extends M.Modal{constructor(t){super(t);this.isCancelled=!1;this.startTime=0;this.currentAbortController=null}onOpen(){let{contentEl:t}=this;t.addClass("translator-progress-modal"),new M.Setting(t).setName("Translating...").setHeading();let s=t.createEl("div",{cls:"translator-status-container"});this.statusEl=s.createEl("p",{text:"Starting...",cls:"translator-status-text"}),this.progressBarContainerEl=t.createEl("div",{cls:"translator-progress-bar-container"}),this.progressBarContainerEl.addClass("is-hidden"),this.progressEl=this.progressBarContainerEl.createEl("div",{cls:"translator-progress-bar-fill"}),this.timeRemainingEl=t.createEl("p",{text:"Estimated time remaining: calculating...",cls:"translator-time-remaining"}),this.logEl=t.createEl("div",{cls:"translator-log-output"});let e=t.createEl("div",{cls:"translator-button-container"});this.cancelButton=e.createEl("button",{text:"Cancel",cls:"translator-cancel-button"}),this.cancelButton.onclick=()=>this.requestCancel(),this.startTime=Date.now()}updateStatus(t,s){if(this.statusEl&&this.statusEl.setText(t),this.progressEl&&s!==void 0&&s>=0){let e=Math.min(100,Math.max(0,s));if(this.progressEl.dataset.progress=String(e),this.progressEl.setText(`${Math.round(e)}%`),this.progressEl.removeClass("is-error"),s>0&&this.startTime>0){let a=(Date.now()-this.startTime)/1e3,o=a/(s/100),l=Math.max(0,o-a);this.timeRemainingEl&&this.timeRemainingEl.setText(`Estimated time remaining: ${this.formatTime(l)}`)}else this.timeRemainingEl&&this.timeRemainingEl.setText("Estimated time remaining: calculating...");this.progressBarContainerEl&&this.progressBarContainerEl.removeClass("is-hidden")}else this.progressEl&&s!==void 0&&s<0&&(this.progressEl.dataset.progress="100",this.progressEl.addClass("is-error"),this.progressEl.setText("Cancelled/Error"),this.timeRemainingEl&&this.timeRemainingEl.setText("Processing stopped."),this.progressBarContainerEl&&this.progressBarContainerEl.removeClass("is-hidden"))}formatTime(t){let s=Math.floor(t/60),e=Math.floor(t%60);return`${s}m ${e}s`}log(t){if(this.logEl){let s=this.logEl.createEl("div",{cls:"translator-log-entry"});s.createEl("span",{text:`[${new Date().toLocaleTimeString()}] `,cls:"translator-log-time"}),s.createEl("span",{text:t,cls:"translator-log-message"}),this.logEl.scrollTop=this.logEl.scrollHeight}}onClose(){let{contentEl:t}=this;t.empty()}get cancelled(){return this.isCancelled}requestCancel(){var t,s;this.isCancelled||(this.isCancelled=!0,this.updateStatus("Cancelling...",-1),this.log("User requested cancellation."),(t=this.currentAbortController)==null||t.abort(),(s=this.cancelButton)==null||s.setAttribute("disabled","true"))}clearDisplay(){var t;(t=this.logEl)==null||t.empty(),this.updateStatus("Starting...",0),this.isCancelled=!1,this.currentAbortController=null,this.cancelButton&&this.cancelButton.removeAttribute("disabled"),this.progressBarContainerEl&&this.progressBarContainerEl.addClass("is-hidden"),this.timeRemainingEl&&this.timeRemainingEl.setText(""),this.startTime=Date.now()}get abortController(){return this.currentAbortController}set abortController(t){this.currentAbortController=t!=null?t:null}};var N=class extends y.Plugin{constructor(){super(...arguments);this.isBusy=!1;this.currentReporter=null}getIsBusy(){return this.isBusy}setBusy(t){this.isBusy=t}async onload(){await this.loadSettings(),this.registerView(P,s=>new S(s,this)),this.addRibbonIcon(Y,W,()=>this.activateView()).addClass("translator-ribbon-class"),this.addCommand({id:"open-translator-sidebar",name:"Open sidebar",callback:()=>this.activateView()}),this.statusBarItem=this.addStatusBarItem(),this.updateStatusBar("Ready"),this.addCommand({id:"translate-and-compare-file",name:"Translate and Compare File",callback:()=>this.translateAndCompareFile()}),this.addSettingTab(new R(this.app,this))}onunload(){}async loadSettings(){this.settings=Object.assign({},A,await this.loadData())}async saveSettings(){await this.saveData(this.settings)}updateStatusBar(t){this.statusBarItem&&this.statusBarItem.setText(`Translator: ${t}`)}async activateView(){let t=this.app.workspace.getLeavesOfType(P);if(t.length>0){this.app.workspace.revealLeaf(t[0]);return}let s=this.app.workspace.getRightLeaf(!1);s?(await s.setViewState({type:P,active:!0}),this.app.workspace.revealLeaf(s)):(console.error("Could not get right sidebar leaf."),new y.Notice("Could not open Translator sidebar."))}getReporter(){var s;let t=(s=this.app.workspace.getLeavesOfType(P)[0])==null?void 0:s.view;if(t instanceof S)return this.app.workspace.revealLeaf(t.leaf),t.clearDisplay(),this.currentReporter=t,t;{let e=new x(this.app);return e.open(),this.currentReporter=e,e}}cancelTranslation(){this.currentReporter&&this.currentReporter.requestCancel()}async translateAndCompareFile(){if(this.isBusy){new y.Notice("Translator is busy.");return}this.isBusy=!0;let t=this.getReporter();t.clearDisplay(),this.updateStatusBar("Translating...");try{let s=this.app.workspace.getActiveFile();if(!s)throw new Error("No active file to translate.");let e=this.settings.providerSettings[this.settings.llmProvider];if(!e||!e.apiKey)throw new Error("API key is not set for the selected provider. Please configure it in the plugin settings.");t.updateStatus("Reading file...",10);let a=await this.app.vault.read(s),o=J(this.settings.llmProvider);t.updateStatus(`Translating with ${this.settings.llmProvider}...`,20);let l=await o.translate(a,this.settings.targetLanguage,this.settings,t);if(t.cancelled)throw new Error("Translation cancelled by user.");t.updateStatus("Creating translated file...",80);let i=`${s.basename}.translated.md`,p=`${this.settings.outputPath}/${i}`;try{await this.app.vault.createFolder(this.settings.outputPath)}catch(g){}let c=this.app.vault.getAbstractFileByPath(p);c&&c instanceof y.TFile?await this.app.vault.modify(c,l):await this.app.vault.create(p,l);let m=this.app.vault.getAbstractFileByPath(p);t.updateStatus("Opening files...",90),await this.app.workspace.getLeaf("split","vertical").openFile(m),t.updateStatus("Translation complete!",100),new y.Notice("Translation complete."),t instanceof x&&setTimeout(()=>t.close(),2e3)}catch(s){let e=s.message||"Unknown error";t.cancelled?(t.log("Translation cancelled by user."),t.updateStatus("Cancelled",-1)):(console.error("Translation Error:",s),new y.Notice("Error during translation. Check the console for details."),t.log(`Error: ${e}`),t.updateStatus("Error",-1))}finally{this.isBusy=!1,this.currentReporter=null,this.updateStatusBar("Ready")}}};
